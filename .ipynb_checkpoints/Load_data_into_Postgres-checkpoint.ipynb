{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylistdir(directory, bit='', end=True):\n",
    "    filelist = os.listdir(directory)\n",
    "    if end:\n",
    "        return [x for x in filelist if x.endswith(f'{bit}') and not x.endswith('.DS_Store') and not x.startswith('Icon')]\n",
    "    else:\n",
    "         return [x for x in filelist if x.startswith(f'{bit}') and not x.endswith('.DS_Store') and not x.startswith('Icon')]\n",
    "        \n",
    "def make_storage_directory(target_dir):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    return target_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Structs():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.inference_table = \"\"\"\n",
    "            CREATE TABLE curr_schema.tab (\n",
    "                entry_id integer PRIMARY KEY,\n",
    "                day date NOT NULL,\n",
    "                hr_min_sec time without time zone NOT NULL,\n",
    "                hub character(3) NOT NULL,\n",
    "                img integer,\n",
    "                audio integer,\n",
    "                env integer,\n",
    "                occupancy integer NOT NULL\n",
    "            )\n",
    "            \"\"\"\n",
    "        \n",
    "        self.drop = \"\"\"\n",
    "        DROP TABLE curr_schema.tab ;\n",
    "        \"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    'host': 'localhost',\n",
    "    'db':'hpd_mobile',\n",
    "    'usr':'maggie',\n",
    "    'pw':'arpa-e'\n",
    "}\n",
    "\n",
    "class PostgreSQL(Structs):\n",
    "    def __init__(self, home_parameters, connection_params=connection_parameters,):\n",
    "        self.P = connection_params\n",
    "        self.home = home_parameters['home']\n",
    "        Structs.__init__(self)\n",
    "        self.inf_table=None\n",
    "    \n",
    "    \n",
    "    def PG_connect(self, execute_statement, sucess_statement):\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                host=self.P['host'], database=self.P['db'], user=self.P['usr'], password=self.P['pw'])\n",
    "            print(f'\\n>Connecting to database: {self.P[\"db\"]}')\n",
    "            cur = conn.cursor()            \n",
    "            cur.execute(execute_statement)\n",
    "            print(sucess_statement)\n",
    "            cur.close()\n",
    "            conn.commit()             \n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(f'Error with connection: {error}')\n",
    "        finally:\n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "                print('>Database connection closed.')\n",
    "                         \n",
    "                \n",
    "    def create_table(self, schema='public'):\n",
    "        table_name = self.home + '_inference'\n",
    "        self.inf_table = f'{schema}.{table_name}'\n",
    "        ex = self.inference_table.replace(\"tab\", table_name).replace(\"curr_schema\", schema)\n",
    "        self.PG_connect(ex, f'Table {table_name} created sucessfully!')\n",
    "        \n",
    "        \n",
    "    def drop_table(self, table_name, schema=\"public\"):\n",
    "        ex = self.drop.replace(\"tab\", table_name).replace(\"curr_schema\", schema)\n",
    "        self.PG_connect(ex, f'Table {table_name} sucessfully dropped.')\n",
    "    \n",
    "    \n",
    "    def insert_table(self, df, table=None):\n",
    "        table = self.inf_table if not table else table\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                host=self.P['host'], database=self.P['db'], user=self.P['usr'], password=self.P['pw'])\n",
    "            print(f'\\n>Connecting to database: {self.P[\"db\"]}')\n",
    "            \n",
    "            tuples = [tuple(x) for x in df.to_numpy()]\n",
    "            cols = ','.join(list(df.columns))\n",
    "            query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "            curr = conn.cursor()\n",
    "            extras.execute_values(curr, query, tuples)\n",
    "            conn.commit()\n",
    "            curr.close()\n",
    "            print(f'Table {table} sucesfully inserted from pandas df.')\n",
    "\n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            print(f'Error with INSERT: {error}') \n",
    "            conn.rollback()\n",
    "            curr.close()\n",
    "        finally:\n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "                print('>Database connection closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       entry_id         day hr_min_sec  hub  env  img  audio  occupancy\n",
      "0             1  2019-03-15   00:00:00  RS1    1    1      0          1\n",
      "1             2  2019-03-15   00:00:10  RS1    1    1      0          1\n",
      "2             3  2019-03-15   00:00:20  RS1    1    1      0          1\n",
      "3             4  2019-03-15   00:00:30  RS1    1    1      0          1\n",
      "4             5  2019-03-15   00:00:40  RS1    1    1      0          1\n",
      "...         ...         ...        ...  ...  ...  ...    ...        ...\n",
      "77755     77756  2019-03-17   23:59:10  RS3    1    1      1          1\n",
      "77756     77757  2019-03-17   23:59:20  RS3    1    1      1          1\n",
      "77757     77758  2019-03-17   23:59:30  RS3    1    1      1          1\n",
      "77758     77759  2019-03-17   23:59:40  RS3    1    1      1          1\n",
      "77759     77760  2019-03-17   23:59:50  RS3    1    1      1          1\n",
      "\n",
      "[77760 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# root_dir = '/Volumes/TOSHIBA-18/H6-black'\n",
    "\n",
    "\n",
    "def read_join(path, save_loc=''):\n",
    "    home_system = os.path.basename(path)\n",
    "    H_num, color = home_system.split('-')\n",
    "    save_path = save_loc  if len(save_loc) > 0 else os.path.join(path, 'Full_inferences')\n",
    "    hub_paths = sorted(glob.glob(f'{path}/Inference_DB/{color[0].upper()}S*'))\n",
    "    hubs = [os.path.basename(hub) for hub in hub_paths]\n",
    "    all_hubs = []\n",
    "    \n",
    "    for h_path in hub_paths:\n",
    "        hub = os.path.basename(h_path)\n",
    "\n",
    "        occupancy = []        \n",
    "        for occ in sorted(glob.glob(f'{path}/Inference_DB/GroundTruth/*.csv')):\n",
    "            occupancy.append(pd.read_csv(occ, index_col='timestamp'))\n",
    "        occupancy_df = pd.concat(occupancy)    \n",
    "        \n",
    "        all_mods = []\n",
    "        mods = mylistdir(h_path, bit='_inf', end=True)\n",
    "        for mod in mods:\n",
    "            dates = sorted(glob.glob(f'{h_path}/{mod}/*.csv'))\n",
    "            day_dfs = []\n",
    "            \n",
    "            for day in dates:\n",
    "                day_dfs.append(pd.read_csv(day, index_col='timestamp'))\n",
    "                \n",
    "            mod_df = pd.concat(day_dfs)\n",
    "            mod_df.columns = [mod.split('_')[0]]\n",
    "            all_mods.append(mod_df)\n",
    "        all_mods.append(occupancy_df)\n",
    "        \n",
    "        for df in all_mods:\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df['hub'] = hub\n",
    "            df.set_index([df.index, 'hub'], inplace=True)\n",
    "        all_hubs.append(pd.concat(all_mods, axis=1, sort=False)) \n",
    "        \n",
    "    df = pd.concat(all_hubs)\n",
    "    \n",
    "    df['date'] = df.index.get_level_values(0)\n",
    "    df.insert(loc=0, column='day', value=df['date'].dt.date)\n",
    "    df.insert(loc=1, column='hr_min_sec', value=df['date'].dt.time)\n",
    "    df.insert(loc=2, column='hub', value=df.index.get_level_values(1))\n",
    "\n",
    "    df.drop(columns=['date'], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df.insert(loc=0, column='entry_id', value = df.index+1)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "    \n",
    "df = read_join('/Users/maggie/Desktop/Inference_DB/H2-red')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">Connecting to database: hpd_mobile\n",
      "Table h2_red_inference sucessfully dropped.\n",
      ">Database connection closed.\n",
      "\n",
      ">Connecting to database: hpd_mobile\n",
      "Table h2_red_inference created sucessfully!\n",
      ">Database connection closed.\n",
      "\n",
      ">Connecting to database: hpd_mobile\n",
      "Table public.h2_red_inference sucesfully inserted from pandas df.\n",
      ">Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "home_parameters = {\n",
    "    'directory': '/Users/maggie/Desktop/Inference_DB/H2-red',\n",
    "    'home': 'h2_red',    \n",
    "}\n",
    "\n",
    "# df = read_join('/Users/maggie/Desktop/Inference_DB/H2-red')\n",
    "\n",
    "pg = PostgreSQL(home_parameters)\n",
    "pg.drop_table('h2_red_inference')\n",
    "\n",
    "pg.create_table()\n",
    "pg.insert_table(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
