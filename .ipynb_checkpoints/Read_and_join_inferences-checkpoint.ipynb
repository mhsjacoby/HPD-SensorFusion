{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylistdir(directory, bit='', end=True):\n",
    "    filelist = os.listdir(directory)\n",
    "    if end:\n",
    "        return [x for x in filelist if x.endswith(f'{bit}') and not x.endswith('.DS_Store') and not x.startswith('Icon')]\n",
    "    else:\n",
    "         return [x for x in filelist if x.startswith(f'{bit}') and not x.endswith('.DS_Store') and not x.startswith('Icon')]\n",
    "        \n",
    "def make_storage_directory(target_dir):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    return target_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         env  img  audio  occupancy\n",
      "timestamp           hub                            \n",
      "2019-03-15 00:00:00 RS1    1    1      0          1\n",
      "2019-03-15 00:00:10 RS1    1    1      0          1\n",
      "2019-03-15 00:00:20 RS1    1    1      0          1\n",
      "2019-03-15 00:00:30 RS1    1    1      0          1\n",
      "2019-03-15 00:00:40 RS1    1    1      0          1\n",
      "...                      ...  ...    ...        ...\n",
      "2019-03-17 23:59:10 RS3    1    1      1          1\n",
      "2019-03-17 23:59:20 RS3    1    1      1          1\n",
      "2019-03-17 23:59:30 RS3    1    1      1          1\n",
      "2019-03-17 23:59:40 RS3    1    1      1          1\n",
      "2019-03-17 23:59:50 RS3    1    1      1          1\n",
      "\n",
      "[77760 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# root_dir = '/Volumes/TOSHIBA-18/H6-black'\n",
    "\n",
    "\n",
    "def read_join(path, save_loc=''):\n",
    "    home_system = os.path.basename(path)\n",
    "    H_num, color = home_system.split('-')\n",
    "    save_path = save_loc  if len(save_loc) > 0 else os.path.join(path, 'Full_inferences')\n",
    "    hub_paths = sorted(glob.glob(f'{path}/Inference_DB/{color[0].upper()}S*'))\n",
    "    hubs = [os.path.basename(hub) for hub in hub_paths]\n",
    "    all_hubs = []\n",
    "    \n",
    "    for h_path in hub_paths:\n",
    "        hub = os.path.basename(h_path)\n",
    "        mods = mylistdir(h_path, bit='_inf', end=True)\n",
    "        occupancy = []\n",
    "        \n",
    "        for occ in sorted(glob.glob(f'{path}/Inference_DB/GroundTruth/*.csv')):\n",
    "            occupancy.append(pd.read_csv(occ, index_col='timestamp'))\n",
    "        occupancy_df = pd.concat(occupancy)    \n",
    "        \n",
    "        all_mods = []\n",
    "        \n",
    "        for mod in mods:\n",
    "            dates = sorted(glob.glob(f'{h_path}/{mod}/*.csv'))\n",
    "            day_dfs = []\n",
    "            \n",
    "            for day in dates:\n",
    "                day_dfs.append(pd.read_csv(day, index_col='timestamp'))\n",
    "                \n",
    "            mod_df = pd.concat(day_dfs)\n",
    "            mod_df.columns = [mod.split('_')[0]]\n",
    "            all_mods.append(mod_df)\n",
    "            \n",
    "        all_mods.append(occupancy_df)\n",
    "        \n",
    "        for df in all_mods:\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df['hub'] = hub\n",
    "            df.set_index([df.index, 'hub'], inplace=True)\n",
    "        all_hubs.append(pd.concat(all_mods, axis=1, sort=False)) \n",
    "        \n",
    "    df = pd.concat(all_hubs)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "df = read_join('/Users/maggie/Desktop/Inference_DB/H2-red')\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['date'] = df.index.get_level_values(0)\n",
    "df.insert(loc=0, column='day', value=df['date'].dt.date)\n",
    "df.insert(loc=1, column='time', value=df['date'].dt.time)\n",
    "\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                day      time  env  img  audio\n",
      "timestamp           hub                                       \n",
      "2019-03-15 00:00:00 RS1  2019-03-15  00:00:00    1    1      1\n",
      "2019-03-15 00:00:10 RS1  2019-03-15  00:00:10    1    1      1\n",
      "2019-03-15 00:00:20 RS1  2019-03-15  00:00:20    1    1      1\n",
      "2019-03-15 00:00:30 RS1  2019-03-15  00:00:30    1    1      1\n",
      "2019-03-15 00:00:40 RS1  2019-03-15  00:00:40    1    1      1\n",
      "...                             ...       ...  ...  ...    ...\n",
      "2019-03-17 23:59:10 RS3  2019-03-17  23:59:10    1    1      1\n",
      "2019-03-17 23:59:20 RS3  2019-03-17  23:59:20    1    1      1\n",
      "2019-03-17 23:59:30 RS3  2019-03-17  23:59:30    1    1      1\n",
      "2019-03-17 23:59:40 RS3  2019-03-17  23:59:40    1    1      1\n",
      "2019-03-17 23:59:50 RS3  2019-03-17  23:59:50    1    1      1\n",
      "\n",
      "[77760 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['date'] = df.index.get_level_values(0)\n",
    "df.insert(loc=0, column='day', value=df['date'].dt.date)\n",
    "df.insert(loc=1, column='time', value=df['date'].dt.time)\n",
    "\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '/Volumes/TOSHIBA-18/H6-black'\n",
    "\n",
    "\n",
    "def read_join(path, save_loc=''):\n",
    "    home_system = os.path.basename(path)\n",
    "    H_num, color = home_system.split('-')\n",
    "    save_path = save_loc  if len(save_loc) > 0 else os.path.join(path, 'Full_inferences')\n",
    "    hub_paths = sorted(glob.glob(f'{path}/Inference_DB/{color[0].upper()}S*'))\n",
    "    hubs = [os.path.basename(hub) for hub in hub_paths]\n",
    "    all_hubs = []\n",
    "    for h_path in hub_paths:\n",
    "        hub = os.path.basename(h_path)\n",
    "        mods = mylistdir(h_path, bit='_inf', end=True)\n",
    "        all_mods = []\n",
    "        occ_days = sorted(glob.glob(f'{path}/Inference_DB/GroundTruth/*.csv'))\n",
    "        occupancy = []\n",
    "        for occ in occ_days:\n",
    "            df = pd.read_csv(occ, index_col='timestamp')\n",
    "            occupancy.append(df)\n",
    "        occupancy_df = pd.concat(occupancy)\n",
    "        for mod in mods:\n",
    "            dates = sorted(glob.glob(f'{h_path}/{mod}/*.csv'))\n",
    "#             df = pd.DataFrame()\n",
    "            day_dfs = []\n",
    "            for day in dates:\n",
    "                day_dfs.append(pd.read_csv(day, index_col='timestamp'))\n",
    "            \n",
    "            \n",
    "            mod_df = pd.concat(day_dfs)\n",
    "#             mod_df.index = pd.to_datetime(mod_df.index)\n",
    "            mod_df.columns = [mod.split('_')[0]]\n",
    "#             mod_df['hub'] = hub\n",
    "#             mod_df.set_index([mod_df.index, 'hub'], inplace=True)\n",
    "#             print(mod_df)\n",
    "            all_mods.append(mod_df)\n",
    "\n",
    "#         all_hubs.append(pd.concat(all_mods, axis=1, sort=False))  \n",
    "\n",
    "        hub_df = pd.concat(all_mods, axis=1, sort=False)\n",
    "        print(hub_df)\n",
    "        \n",
    "#         mod_df = pd.concat(day_dfs)\n",
    "#         mod_df.index = pd.to_datetime(mod_df.index)\n",
    "#         mod_df.columns = [mod.split('_')[0]]\n",
    "#         mod_df['hub'] = hub\n",
    "#         mod_df.set_index([mod_df.index, 'hub'], inplace=True)\n",
    "        \n",
    "# #         all_hubs.append(pd.concat(all_mods, axis=1, sort=False))    \n",
    "#     df = pd.concat(all_hubs)\n",
    "    \n",
    "#     occ_days = sorted(glob.glob(f'{path}/Inference_DB/GroundTruth/*.csv'))\n",
    "#     print(occ_days)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "df = read_join('/Users/maggie/Desktop/Inference_DB/H2-red')\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df['date'] = df.index.get_level_values(0)\n",
    "# df.insert(loc=0, column='day', value=df['date'].dt.date)\n",
    "# df.insert(loc=1, column='time', value=df['date'].dt.time)\n",
    "\n",
    "# df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
